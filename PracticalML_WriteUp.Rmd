---
title: "PracticalML_WriteUp"
author: "Kapil Wadodkar"
date: "21 June 2015"
output: html_document
---

# PracticalMachineLearning
==============================================
  
# Problem Description
> Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

# Solution Details

## Basic setup
Basic setup to make this research reproducible:
```r
library(caret)
set.seed(12345)
```

## Setting up and cleaning data.
With initial analysis removing first 7 columns of data which appears to be of no use in analysis:

```r
#Training Data.
rawData <- read.csv("pml-training.csv")

## Removing unwanted data
# 1. Remove unwanted columns (e.g. columns containing names, or irrelevant informaton)
trainingData <- subset(rawData, select=-c(1:7))
```

Removing Near-Zero-Variance columns as those are not contributing for prediction

```r
# 2. Removing nearZeroValues 
nzv <- nearZeroVar(trainingData)
trainingData <- trainingData[,-nzv]
```

Removing NA's for obvious reasons:

```r
# 3. Removing NA's.
completeColumns <- (colSums(is.na(trainingData)) == 0)
trainingData <- subset(trainingData, select=completeColumns)
classeColumn <- dim(trainingData)[2] # Classe column is the last column
trainingData[, -classeColumn] <- apply(trainingData[, -classeColumn], 2, function(x) as.numeric(as.character(x)))
```

## Spliting, training and validating data sets
70-30 ratio preferred for splitting training data.

```r
inTrain <- createDataPartition(y = trainingData$classe, p=0.7, list=FALSE)
training <- trainingData[inTrain,]
testing <- trainingData[-inTrain,]
```

## Training
Pre-processing the datasets to center and scaling the values.
Training with RandomForest method for better results against this complex classification.

```r
trainingControl <- trainControl(method = "cv", number = 4, allowParallel = TRUE)
modelFit <- train(training$classe ~. , data = training, method = "rf", trControl = trainingControl, preProcess = c("center","scale"))
```

## Out of sample error
Keeping error to minimum with current training:
  
```r
modelFit$finalModel
```

Considering confusion matrix to asses implied algorithm:
  
```r
predictions <- predict(modelFit, testing)
confusionMatrix(predictions, testing$classe)
```

Manual calculations for accuracy to reassure:
  
```r
sum(predictions == testing$classe) / nrow(testing)
```

The implied prediction algorithm is with Out-Of-Sample Error is in acceptable range.
  
## Prediction 
Predicting  implied algorithm against pml-testing.csv with `predict` on our data:
  
```r
predictionData <- read.csv("pml-testing.csv")
predictResults <- predict(modelFit, newdata=predictionData)
predictResults
```